---
title: "hw_5"
author: "Kun Zhou"
date: "February 29, 2016"
output: pdf_document
header_includes:
- \usepackage{amsmath}
---

1.
\begin{flalign*}
&f(x) = x^n - na\log x&\\
&f'(x) = nx^{n-1} - \frac{na}{x}&\\
&f''(x) = n(n-1)x^{n-2} - \frac{na}{x^2}&\\
&n \geq 1 \Rightarrow n(n-1) \geq 0 \Rightarrow f''(x)\geq 0 \Rightarrow f(x) \text{ is convex}& \\
&f'(x) = 0 \Rightarrow x_{\min} = a^{\frac{1}{n}}&
\end{flalign*}
```{r, fig.width=5, fig.height=2.5}
newton <- function(par, n, a)
{
  tra = NULL
  last = par
  count = 0
  while(abs(n * last^(n-1) - n*a/last) > 1e-6)  #repeat the process until f' is almost 0 
  {
    now = last - (n * last^(n-1) - n*a/last) / (n*(n-1)*last^(n-2) + n*a/(last^2))
    count = count + 1
    last = now
    tra = c(tra, last)
  }
  return(list(result = last, step = count, trace = tra))
}
# f(x)
fun <- function(x, n, a)
{
  return((x^n - n * a * log(x)))
}

# initial position = 1, n =2, a = 100
x = seq(0.1,40, 0.1) 
plot(x, fun(x, 2, 100), type="l", ylab="f(x)")
newton(1, 2, 100)


```
I set $a = 100$.  It takes 10 7 steps to reach the optimum point.  The $\{x_k\}$ is also shown above. 

2.
\begin{flalign*}
&v_1=u_1&\\
&v_2 = u_2 - \frac{u_2^tAv_1}{v_1^tAv_1}v_1 \Rightarrow  v_2^tAv_1 = (u_2 - \frac{u_2^tAv_1}{v_1^tAv_1}v_1)^tA v_1 = u_2^tA v_1 - \frac{u_2^tAv_1}{v_1^tAv_1} v_1^tAv_1 = 0 \Rightarrow v_1,v_2\text{are conjugate.}&\\
&\text{Assume } v_k \text{ is conjugate with } v_1,\ldots, v_{k-1}. &\\
&v_{k+1} = u_{k+1}^t -\sum_{j=1}^{k}\frac{u_{k+1}^tAv_j}{v_j^tAv_j}v_j \Rightarrow \text{For }i=1,\ldots,k,  &\\
&v_{k+1}^tAv_i = (u_{k+1}^t -\sum_{j=1}^{k}\frac{u_{k+1}^tAv_j}{v_j^tAv_j}v_j)^tAv_i&\\
&= u_{k+1}^tAv_i - \sum_{j=1}^{k}\frac{u_{k+1}^tAv_j}{v_j^tAv_j}v_j^tAv_i&\\
&= u_{k+1}^tAv_i  - \frac{u_{k+1}^tAv_i}{v_i^tAv_i}v_i^tAv_i\qquad \text{since }v_j^tAv_i = 0\text{ if }i\neq j&\\
&=0&\\
&\text{Thus }\{v_1, \ldots, v_n\} \text{ are conjugate.} &\\
&\text{If } v_n \text{ is the combination of }v_1,\ldots, v_{n-1}, \exists i, v_n^tAv_i = (a_1v_1 + \ldots a_{n-1}v_{n-1})^tAv_i \neq 0 \text{ which is not true.}&\\
&\text{Thus }\{v_1, \ldots, v_n\} \text{ provide a basis.}&
\end{flalign*}

3.


```{r}
#conjugate gradient
CG<-function(ini.x, A, b)
{
  x = matrix(ini.x)
  v = A %*% x + b
  step = 0
  for(i in 1:nrow(A))
  {
    t = as.numeric(-t(A %*% x + b) %*% v / (t(v) %*% A %*% v))
    x = x + t * v
    step = step + 1
    print(list(step=step, v=v, x=x))
    alpha = as.numeric(t(A %*% x + b) %*% A %*% v / (t(v) %*% A %*% v))
    v = -(A %*% x + b) + alpha * v
  }
}
#BFGS
BFGS <- function(ini.x, ini.H, A, b)
{
  x = ini.x
  H = ini.H
  step = 0
 
  for(i in 1:nrow(A))
  {
    v = -solve(H, A %*% x + b)
    t = -as.numeric(t(A %*% x + b) %*% v / (t(v) %*% A %*% v))
    x2 = x + t * v
    s = t * v
    y = A %*% (x2 - x)
    H = H + y %*% t(y) / as.numeric(t(y) %*% s) - H %*% s %*% t(s) %*% H /
      as.numeric(t(s) %*% H %*% s)
    x = x2
    step = step + 1
    print(list(step=step, H=H, v=v, x=x))
  }
}

A = matrix(c(2,1,1,1),nrow=2)
b = matrix(c(1,1))
x=matrix(c(0,0))
H = diag(2)
v = matrix(c(-1, -1))

CG(x, A, b)
BFGS(x, H, A, b)
```
From the aforementioned results, the two consequences of iterates coincinde.  The following is the results from $\mathop{optim}$
```{r}
fun <- function(x, A, b)
{
  x = matrix(x)
  result = 0.5 * t(x) %*% A %*% x + t(x) %*% b
  return(as.numeric(result))
}
optim(par=x, fn = fun, A = A, b = b, method = "CG")
optim(par=x, fn = fun, A = A, b = b, method = "BFGS")
```
The function $\mathop{optim}$ gets the same result that $(0, -1)^{\top}$ is the point minimizes $f(x)$. 



